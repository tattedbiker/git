Packfile URIs
=============

This feature allows servers to serve part of their packfile response as URIs.
This allows server designs that improve scalability in bandwidth and CPU usage
(for example, by serving some data through a CDN), and (in the future) provides
some measure of resumability to clients.

This feature is available only in protocol version 2.

Protocol
--------

The server advertises `packfile-uris`.

If the client then communicates which protocols (HTTPS, etc.) it supports with
a `packfile-uris` argument, the server MAY send a `packfile-uris` section
directly before the `packfile` section (right after `wanted-refs` if it is
sent) containing URIs of any of the given protocols. The URIs point to
packfiles that use only features that the client has declared that it supports
(e.g. ofs-delta and thin-pack). See protocol-v2.txt for the documentation of
this section.

Clients then should understand that the returned packfile could be incomplete,
and that it needs to download all the given URIs before the fetch or clone is
complete.

Server design
-------------

The server can be trivially made compatible with the proposed protocol by
having it advertise `packfile-uris`, tolerating the client sending
`packfile-uris`, and never sending any `packfile-uris` section. But we should
include some sort of non-trivial implementation in the Minimum Viable Product,
at least so that we can test the client.

This is the implementation: a feature, marked experimental, that allows the
server to be configured by one or more `uploadpack.blobPackfileUri=<sha1>
<uri>` entries. Whenever the list of objects to be sent is assembled, a blob
with the given sha1 can be replaced by the given URI. This allows, for example,
servers to delegate serving of large blobs to CDNs.

Client design
-------------

While fetching, the client needs to remember the list of URIs and cannot
declare that the fetch is complete until all URIs have been downloaded as
packfiles.

The division of work (initial fetch + additional URIs) introduces convenient
points for resumption of an interrupted clone - such resumption can be done
after the Minimum Viable Product (see "Future work").

The client can inhibit this feature (i.e. refrain from sending the
`packfile-uris` parameter) by passing --no-packfile-uris to `git fetch`.

Future work
-----------

The protocol design allows some evolution of the server and client without any
need for protocol changes, so only a small-scoped design is included here to
form the MVP. For example, the following can be done:

 * On the server, a long-running process that takes in entire requests and
   outputs a list of URIs and the corresponding inclusion and exclusion sets of
   objects. This allows, e.g., signed URIs to be used and packfiles for common
   requests to be cached.
 * On the client, resumption of clone. If a clone is interrupted, information
   could be recorded in the repository's config and a "clone-resume" command
   can resume the clone in progress. (Resumption of subsequent fetches is more
   difficult because that must deal with the user wanting to use the repository
   even after the fetch was interrupted.)

There are some possible features that will require a change in protocol:

 * Additional HTTP headers (e.g. authentication)
 * Byte range support
 * Different file formats referenced by URIs (e.g. raw object)
